{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uhgiEOoNEyu"
      },
      "source": [
        "# HLCV Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62OCVFrnRZGx"
      },
      "outputs": [],
      "source": [
        "Name = \"Luisa Danalachi\"\n",
        "Matriculation_Number = \"7022909\"\n",
        "\n",
        "Name = \"Victor Martinez Palomares\"\n",
        "Matriculation_Number = \"7021729\"\n",
        "\n",
        "Name = \"Soham Roy\"\n",
        "Matriculation_Number = \"7028704\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6fBKi5dRdVQ",
        "outputId": "39f4df39-bf17-465d-bb19-ec6c24c10da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')\n",
        "\n",
        " !mkdir ./datasets\n",
        " !mkdir ./datasets/lyme_dataset\n",
        " !cp -r drive/MyDrive/archive.zip ./datasets\n",
        " !unzip -q -o \"./datasets/archive.zip\" -d \"./datasets/lyme_dataset\"\n",
        "\n",
        "# '''\n",
        "# !mkdir ./resources\n",
        "\n",
        "# !cp -r drive/MyDrive/Colab\\ Notebooks/HLCV/Exercise_3/resources/fig1.png ./resources\n",
        "# !cp -r drive/MyDrive/Colab\\ Notebooks/HLCV/Exercise_3/resources/fig2.png ./resources\n",
        "\n",
        "# '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0JRXLHzNEy1"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nifGyyAjRiJd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRgAQ3OtKLeE"
      },
      "source": [
        "### Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTnqkXkIKKs8",
        "outputId": "9a0fef02-0352-4a18-d469-180bbdbadb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SIZE = 256\n",
        "EPOCHS = 120\n",
        "BATCH = 20\n",
        "LR = 1e-4\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: %s'%device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K_y-5gkNEy4"
      },
      "source": [
        "# Define data augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc02dP-sWBLl"
      },
      "outputs": [],
      "source": [
        "data_aug_transforms = []\n",
        "\n",
        "data_aug_transforms.append(transforms.RandomRotation([-90, 90]) ) \n",
        "data_aug_transforms.append( transforms.RandomHorizontalFlip() )\n",
        "data_aug_transforms.append(transforms.ColorJitter(brightness = 0.2)) \n",
        "\n",
        "norm_transforms = [transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "                   transforms.ToTensor(), \n",
        "                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "\n",
        "train_transforms = transforms.Compose(data_aug_transforms + norm_transforms)\n",
        "\n",
        "# Add Compose\n",
        "test_transforms =transforms.Compose(norm_transforms) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyQNa26XNEy6"
      },
      "source": [
        "# Load Lyme DS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdLU5BCKNEy6",
        "outputId": "79d05572-6f9d-45f5-b0cd-cd763e0ce16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lyme Dermnet data: Dataset ImageFolder\n",
            "    Number of datapoints: 357\n",
            "    Root location: ./datasets/lyme_dataset/RashData/Train/Train_2_Cases\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ColorJitter(brightness=[0.8, 1.2], contrast=None, saturation=None, hue=None)\n",
            "               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n",
            "87\n",
            "Lyme classes: ['Lyme_Negative', 'Lyme_Positive']\n"
          ]
        }
      ],
      "source": [
        "#Load Lyme\n",
        "lyme_train_data_path = \"./datasets/lyme_dataset/RashData/Train/Train_2_Cases\"\n",
        "lyme_test_data_path = \"./datasets/lyme_dataset/RashData/Validation/Validation_2_Cases\"\n",
        "\n",
        "# ImageFolder is a generic data loader where the images are arranged in multiple folders\n",
        "\n",
        "#Load TRAIN\n",
        "lyme_train_data = torchvision.datasets.ImageFolder(root=lyme_train_data_path, transform=train_transforms)\n",
        "lyme_train_data_loader = data.DataLoader(lyme_train_data, batch_size=BATCH, shuffle=True)\n",
        "print(\"Lyme Dermnet data:\", lyme_train_data)\n",
        "\n",
        "# Load TEST \n",
        "lyme_test_data = torchvision.datasets.ImageFolder(root=lyme_test_data_path, transform=test_transforms)\n",
        "lyme_test_data_loader = data.DataLoader(lyme_test_data, batch_size=BATCH)\n",
        "print(len(lyme_test_data))\n",
        "# Check list of classes\n",
        "# Are converted to 0,1 etc when call enumerate()\n",
        "list_of_classes=list(map(str, list(lyme_train_data.classes)) )\n",
        "print(\"Lyme classes:\", list_of_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWOfr-rlNEy7"
      },
      "source": [
        "# Train val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GamAvPRwNEy8",
        "outputId": "1ac89135-8bb9-4949-8649-4264439c017a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "321\n",
            "36\n",
            "87\n",
            "16\n",
            "1\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "val_split = 0.1\n",
        "\n",
        "num_training = int((1 - val_split) * len(lyme_train_data))\n",
        "num_validation = len(lyme_train_data) - num_training\n",
        "mask = list(range(num_training))\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(lyme_train_data, mask)\n",
        "mask = list(range(num_training, num_training + num_validation))\n",
        "val_dataset = torch.utils.data.Subset(lyme_train_data, mask)\n",
        "\n",
        "# Create DataLoaders\n",
        "lyme_train_data_loader = data.DataLoader(train_dataset, batch_size=BATCH, shuffle=True, drop_last=True)\n",
        "lyme_validation_data_loader = data.DataLoader(val_dataset, batch_size=BATCH, shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "print(len(lyme_test_data))\n",
        "\n",
        "print(len(lyme_train_data_loader))\n",
        "print(len(lyme_validation_data_loader))\n",
        "print(len(lyme_test_data_loader)) #did not add drop_last=True to TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0qM5ynNNEy8"
      },
      "source": [
        "## Check dataloader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcAqxJVRNEy9"
      },
      "outputs": [],
      "source": [
        "# iterator=iter(lyme_validation_data_loader)\n",
        "# inputs, classes = next(iterator)\n",
        "# print(len(inputs)) \n",
        "\n",
        "# plt.imshow(inputs[0].squeeze().permute(2,1,0))\n",
        "# plt.show()\n",
        "# print(\"CLass: \",classes[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAsB7nhiNEy9"
      },
      "source": [
        "# Load Dermnet DS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q -o \"./drive/MyDrive/dermnet.zip\" -d \"./datasets/\""
      ],
      "metadata": {
        "id": "9pd5X5z_ibAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3qCELasNEy9",
        "outputId": "ec17ecbc-0ca5-415b-b495-027a0ddf55c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Details Dermnet data: Dataset ImageFolder\n",
            "    Number of datapoints: 15557\n",
            "    Root location: ./datasets/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ColorJitter(brightness=[0.8, 1.2], contrast=None, saturation=None, hue=None)\n",
            "               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n",
            "Dermnet classes ['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
          ]
        }
      ],
      "source": [
        "#Load Dermnet\n",
        "dermnet_train_data_path = \"./datasets/train\"\n",
        "dermnet_test_data_path = \"./datasets/test\"\n",
        "\n",
        "# ImageFolder is a generic data loader where the images are arranged in multiple folders\n",
        "dermnet_train_data = torchvision.datasets.ImageFolder(root=dermnet_train_data_path, transform=train_transforms)\n",
        "dermnet_train_data_loader = data.DataLoader(dermnet_train_data, batch_size=BATCH, shuffle=True)\n",
        "print(\"Details Dermnet data:\", dermnet_train_data)\n",
        "\n",
        "# Load test \n",
        "dermnet_test_data = torchvision.datasets.ImageFolder(root=dermnet_test_data_path, transform=test_transforms)\n",
        "dermnet_test_data_loader = data.DataLoader(dermnet_train_data, batch_size=BATCH)\n",
        "\n",
        "# Load list of classes\n",
        "list_of_classes=list(map(str, list(dermnet_train_data.classes)) )\n",
        "print(\"Dermnet classes\", list_of_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_of_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44_ojbvcoU1C",
        "outputId": "50ad5630-bb66-4001-a343-e61f414fb049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4qhaNWeNEy-"
      },
      "source": [
        "# Load HAM DS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc4b0EtzNEy-",
        "outputId": "1ce7a311-647d-4be8-88f8-80da59447979"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ham_df = pd.read_csv('./datasets/HAM10000/HAM10000_metadata.csv')\n",
        "ham_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVm-Ek-hNEy_"
      },
      "source": [
        "## Extract images based on their label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "8EB7uZafNEy_"
      },
      "outputs": [],
      "source": [
        "# Take labels\n",
        "name_labels = ham_df[\"dx\"].unique()\n",
        "\n",
        "# Create folders with the label name and add the corresponding images -> Must for using ImageFolder!\n",
        "\n",
        "for label in range(len(name_labels)):\n",
        "    # create folder for each label\n",
        "    label_folder_path = \"./datasets/HAM10000/train/\" + str(name_labels[label])\n",
        "    \n",
        "    # check is path exists if not create folder\n",
        "    if not os.path.exists(label_folder_path):\n",
        "        os.mkdir('./datasets/HAM10000/train/' + name_labels[label] + \"/\" )\n",
        "    \n",
        "    # take the image id corresponding to label\n",
        "    image_names =  ham_df[ham_df['dx'] == name_labels[label]]['image_id']\n",
        "    \n",
        "    # iterate through all image names \n",
        "    for image in image_names:\n",
        "        # create the path for image: either part 1 or part 2\n",
        "        path_folder_1 = \"./datasets/HAM10000/HAM10000_images_part_1/\" + image + \".jpg\"\n",
        "        path_folder_2 = \"./datasets/HAM10000/HAM10000_images_part_2/\" + image + \".jpg\"\n",
        "        \n",
        "        # find where is the image and copy it into the label folder\n",
        "        if os.path.exists(path_folder_1):\n",
        "            shutil.copyfile(path_folder_1, './datasets/HAM10000/train/' + name_labels[label] + \"/\" + image + \".jpg\")\n",
        "        else:\n",
        "            shutil.copyfile(path_folder_2, './datasets/HAM10000/train/' + name_labels[label] + \"/\" + image + \".jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-2jXCNONEy_"
      },
      "source": [
        "## Load data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBd-7iaeNEzA",
        "outputId": "c6766d42-cfd6-4c82-8475-3ab19aadc1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HAM1000 Dermnet data: Dataset ImageFolder\n",
            "    Number of datapoints: 10015\n",
            "    Root location: ./datasets/HAM10000/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ColorJitter(brightness=[0.8, 1.2], contrast=None, saturation=None, hue=None)\n",
            "               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n",
            "HAM1000 classes ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
          ]
        }
      ],
      "source": [
        "#Load Dermnet\n",
        "HAM_train_data_path = \"./datasets/HAM10000/train\"\n",
        "\n",
        "# ImageFolder is a generic data loader where the images are arranged in multiple folders\n",
        "ham_train_data = torchvision.datasets.ImageFolder(root=HAM_train_data_path, transform=train_transforms)\n",
        "ham_train_data_loader = data.DataLoader(ham_train_data, batch_size=BATCH, shuffle=True)\n",
        "print(\"HAM1000 Dermnet data:\", ham_train_data)\n",
        "\n",
        "# # Load list of classes\n",
        "list_of_classes=list(map(str, list(ham_train_data.classes)) )\n",
        "print(\"HAM1000 classes\", list_of_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSDvF5JPQbDS"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ResNet50"
      ],
      "metadata": {
        "id": "QN04M8e7aDVM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct4o47mpQeMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cdfd1e6-36df-4f99-fb0a-11f46df97e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50(\n",
            "  (net): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Flatten(start_dim=1, end_dim=-1)\n",
            "      (1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.4, inplace=False)\n",
            "      (4): ReLU()\n",
            "      (5): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (7): Dropout(p=0.4, inplace=False)\n",
            "      (8): ReLU()\n",
            "      (9): Linear(in_features=256, out_features=23, bias=True)\n",
            "      (10): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (11): Dropout(p=0.4, inplace=False)\n",
            "      (12): ReLU()\n",
            "      (13): Linear(in_features=23, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Params to learn:\n",
            "\t net.conv1.weight\n",
            "\t net.bn1.weight\n",
            "\t net.bn1.bias\n",
            "\t net.layer1.0.conv1.weight\n",
            "\t net.layer1.0.bn1.weight\n",
            "\t net.layer1.0.bn1.bias\n",
            "\t net.layer1.0.conv2.weight\n",
            "\t net.layer1.0.bn2.weight\n",
            "\t net.layer1.0.bn2.bias\n",
            "\t net.layer1.0.conv3.weight\n",
            "\t net.layer1.0.bn3.weight\n",
            "\t net.layer1.0.bn3.bias\n",
            "\t net.layer1.0.downsample.0.weight\n",
            "\t net.layer1.0.downsample.1.weight\n",
            "\t net.layer1.0.downsample.1.bias\n",
            "\t net.layer1.1.conv1.weight\n",
            "\t net.layer1.1.bn1.weight\n",
            "\t net.layer1.1.bn1.bias\n",
            "\t net.layer1.1.conv2.weight\n",
            "\t net.layer1.1.bn2.weight\n",
            "\t net.layer1.1.bn2.bias\n",
            "\t net.layer1.1.conv3.weight\n",
            "\t net.layer1.1.bn3.weight\n",
            "\t net.layer1.1.bn3.bias\n",
            "\t net.layer1.2.conv1.weight\n",
            "\t net.layer1.2.bn1.weight\n",
            "\t net.layer1.2.bn1.bias\n",
            "\t net.layer1.2.conv2.weight\n",
            "\t net.layer1.2.bn2.weight\n",
            "\t net.layer1.2.bn2.bias\n",
            "\t net.layer1.2.conv3.weight\n",
            "\t net.layer1.2.bn3.weight\n",
            "\t net.layer1.2.bn3.bias\n",
            "\t net.layer2.0.conv1.weight\n",
            "\t net.layer2.0.bn1.weight\n",
            "\t net.layer2.0.bn1.bias\n",
            "\t net.layer2.0.conv2.weight\n",
            "\t net.layer2.0.bn2.weight\n",
            "\t net.layer2.0.bn2.bias\n",
            "\t net.layer2.0.conv3.weight\n",
            "\t net.layer2.0.bn3.weight\n",
            "\t net.layer2.0.bn3.bias\n",
            "\t net.layer2.0.downsample.0.weight\n",
            "\t net.layer2.0.downsample.1.weight\n",
            "\t net.layer2.0.downsample.1.bias\n",
            "\t net.layer2.1.conv1.weight\n",
            "\t net.layer2.1.bn1.weight\n",
            "\t net.layer2.1.bn1.bias\n",
            "\t net.layer2.1.conv2.weight\n",
            "\t net.layer2.1.bn2.weight\n",
            "\t net.layer2.1.bn2.bias\n",
            "\t net.layer2.1.conv3.weight\n",
            "\t net.layer2.1.bn3.weight\n",
            "\t net.layer2.1.bn3.bias\n",
            "\t net.layer2.2.conv1.weight\n",
            "\t net.layer2.2.bn1.weight\n",
            "\t net.layer2.2.bn1.bias\n",
            "\t net.layer2.2.conv2.weight\n",
            "\t net.layer2.2.bn2.weight\n",
            "\t net.layer2.2.bn2.bias\n",
            "\t net.layer2.2.conv3.weight\n",
            "\t net.layer2.2.bn3.weight\n",
            "\t net.layer2.2.bn3.bias\n",
            "\t net.layer2.3.conv1.weight\n",
            "\t net.layer2.3.bn1.weight\n",
            "\t net.layer2.3.bn1.bias\n",
            "\t net.layer2.3.conv2.weight\n",
            "\t net.layer2.3.bn2.weight\n",
            "\t net.layer2.3.bn2.bias\n",
            "\t net.layer2.3.conv3.weight\n",
            "\t net.layer2.3.bn3.weight\n",
            "\t net.layer2.3.bn3.bias\n",
            "\t net.layer3.0.conv1.weight\n",
            "\t net.layer3.0.bn1.weight\n",
            "\t net.layer3.0.bn1.bias\n",
            "\t net.layer3.0.conv2.weight\n",
            "\t net.layer3.0.bn2.weight\n",
            "\t net.layer3.0.bn2.bias\n",
            "\t net.layer3.0.conv3.weight\n",
            "\t net.layer3.0.bn3.weight\n",
            "\t net.layer3.0.bn3.bias\n",
            "\t net.layer3.0.downsample.0.weight\n",
            "\t net.layer3.0.downsample.1.weight\n",
            "\t net.layer3.0.downsample.1.bias\n",
            "\t net.layer3.1.conv1.weight\n",
            "\t net.layer3.1.bn1.weight\n",
            "\t net.layer3.1.bn1.bias\n",
            "\t net.layer3.1.conv2.weight\n",
            "\t net.layer3.1.bn2.weight\n",
            "\t net.layer3.1.bn2.bias\n",
            "\t net.layer3.1.conv3.weight\n",
            "\t net.layer3.1.bn3.weight\n",
            "\t net.layer3.1.bn3.bias\n",
            "\t net.layer3.2.conv1.weight\n",
            "\t net.layer3.2.bn1.weight\n",
            "\t net.layer3.2.bn1.bias\n",
            "\t net.layer3.2.conv2.weight\n",
            "\t net.layer3.2.bn2.weight\n",
            "\t net.layer3.2.bn2.bias\n",
            "\t net.layer3.2.conv3.weight\n",
            "\t net.layer3.2.bn3.weight\n",
            "\t net.layer3.2.bn3.bias\n",
            "\t net.layer3.3.conv1.weight\n",
            "\t net.layer3.3.bn1.weight\n",
            "\t net.layer3.3.bn1.bias\n",
            "\t net.layer3.3.conv2.weight\n",
            "\t net.layer3.3.bn2.weight\n",
            "\t net.layer3.3.bn2.bias\n",
            "\t net.layer3.3.conv3.weight\n",
            "\t net.layer3.3.bn3.weight\n",
            "\t net.layer3.3.bn3.bias\n",
            "\t net.layer3.4.conv1.weight\n",
            "\t net.layer3.4.bn1.weight\n",
            "\t net.layer3.4.bn1.bias\n",
            "\t net.layer3.4.conv2.weight\n",
            "\t net.layer3.4.bn2.weight\n",
            "\t net.layer3.4.bn2.bias\n",
            "\t net.layer3.4.conv3.weight\n",
            "\t net.layer3.4.bn3.weight\n",
            "\t net.layer3.4.bn3.bias\n",
            "\t net.layer3.5.conv1.weight\n",
            "\t net.layer3.5.bn1.weight\n",
            "\t net.layer3.5.bn1.bias\n",
            "\t net.layer3.5.conv2.weight\n",
            "\t net.layer3.5.bn2.weight\n",
            "\t net.layer3.5.bn2.bias\n",
            "\t net.layer3.5.conv3.weight\n",
            "\t net.layer3.5.bn3.weight\n",
            "\t net.layer3.5.bn3.bias\n",
            "\t net.layer4.0.conv1.weight\n",
            "\t net.layer4.0.bn1.weight\n",
            "\t net.layer4.0.bn1.bias\n",
            "\t net.layer4.0.conv2.weight\n",
            "\t net.layer4.0.bn2.weight\n",
            "\t net.layer4.0.bn2.bias\n",
            "\t net.layer4.0.conv3.weight\n",
            "\t net.layer4.0.bn3.weight\n",
            "\t net.layer4.0.bn3.bias\n",
            "\t net.layer4.0.downsample.0.weight\n",
            "\t net.layer4.0.downsample.1.weight\n",
            "\t net.layer4.0.downsample.1.bias\n",
            "\t net.layer4.1.conv1.weight\n",
            "\t net.layer4.1.bn1.weight\n",
            "\t net.layer4.1.bn1.bias\n",
            "\t net.layer4.1.conv2.weight\n",
            "\t net.layer4.1.bn2.weight\n",
            "\t net.layer4.1.bn2.bias\n",
            "\t net.layer4.1.conv3.weight\n",
            "\t net.layer4.1.bn3.weight\n",
            "\t net.layer4.1.bn3.bias\n",
            "\t net.layer4.2.conv1.weight\n",
            "\t net.layer4.2.bn1.weight\n",
            "\t net.layer4.2.bn1.bias\n",
            "\t net.layer4.2.conv2.weight\n",
            "\t net.layer4.2.bn2.weight\n",
            "\t net.layer4.2.bn2.bias\n",
            "\t net.layer4.2.conv3.weight\n",
            "\t net.layer4.2.bn3.weight\n",
            "\t net.layer4.2.bn3.bias\n",
            "\t net.fc.1.weight\n",
            "\t net.fc.1.bias\n",
            "\t net.fc.2.weight\n",
            "\t net.fc.2.bias\n",
            "\t net.fc.5.weight\n",
            "\t net.fc.5.bias\n",
            "\t net.fc.6.weight\n",
            "\t net.fc.6.bias\n",
            "\t net.fc.9.weight\n",
            "\t net.fc.9.bias\n",
            "\t net.fc.10.weight\n",
            "\t net.fc.10.bias\n",
            "\t net.fc.13.weight\n",
            "\t net.fc.13.bias\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet50(\n",
              "  (net): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=2048, out_features=512, bias=True)\n",
              "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): Dropout(p=0.4, inplace=False)\n",
              "      (4): ReLU()\n",
              "      (5): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (7): Dropout(p=0.4, inplace=False)\n",
              "      (8): ReLU()\n",
              "      (9): Linear(in_features=256, out_features=23, bias=True)\n",
              "      (10): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (11): Dropout(p=0.4, inplace=False)\n",
              "      (12): ReLU()\n",
              "      (13): Linear(in_features=23, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from torchvision import models\n",
        "#from torchvision.models import ResNet50_Weights\n",
        "\n",
        "layer_config= [2048, 512, 256]\n",
        "num_classes = 1\n",
        "num_epochs = 30\n",
        "batch_size = 200\n",
        "learning_rate = 1e-5\n",
        "learning_rate_decay = 0.99\n",
        "\n",
        "# Create ResNet 50 model pretrained with ImageNet\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, n_class, fine_tune, pretrained=True):\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.net = models.resnet50(pretrained=pretrained)\n",
        "        \n",
        "        # add new classifier layers\n",
        "        self.net.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(layer_config[0], layer_config[1]),\n",
        "            nn.BatchNorm1d(layer_config[1]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[1], layer_config[2]),\n",
        "            nn.BatchNorm1d(layer_config[2]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[2], 23),\n",
        "            nn.BatchNorm1d(23),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(23, 1)\n",
        "        )       \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        #return out\n",
        "        return out.view(-1, 1).squeeze(1).type(torch.FloatTensor) \n",
        "\n",
        "# Initialize the model for this run\n",
        "fine_tune = True\n",
        "pretrained = True\n",
        "model= ResNet50(num_classes, fine_tune, pretrained)\n",
        "model.load_state_dict(torch.load('./bestmodel_resnet_dermnet.ckpt'), strict=False)\n",
        "print(model)\n",
        "\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "if fine_tune:\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    params_to_update = model.parameters()\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###vgg16"
      ],
      "metadata": {
        "id": "u2BI1T5ZaKPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "layer_config= [2048, 512, 256]\n",
        "num_classes = 1\n",
        "num_epochs = 30\n",
        "batch_size = 200\n",
        "learning_rate = 1e-5\n",
        "learning_rate_decay = 0.99\n",
        "\n",
        "# Create vgg16 model pretrained with ImageNet\n",
        "class vgg16(nn.Module):\n",
        "    def __init__(self, n_class, fine_tune, pretrained=True):\n",
        "        super(vgg16, self).__init__()\n",
        "        self.net = models.vgg16(pretrained=pretrained)\n",
        "        \n",
        "        # add new classifier layers\n",
        "        self.net.classifier[6] = (nn.Sequential(\n",
        "            nn.Linear(4096, layer_config[0]),\n",
        "            nn.BatchNorm1d(layer_config[0]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[0], layer_config[1]),\n",
        "            nn.BatchNorm1d(layer_config[1]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[1], layer_config[2]),\n",
        "            nn.BatchNorm1d(layer_config[2]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[2], 1)\n",
        "        ))       \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        #return out\n",
        "        return out.view(-1, 1).squeeze(1).type(torch.FloatTensor) \n",
        "\n",
        "# Initialize the model for this run\n",
        "fine_tune = True\n",
        "pretrained = True\n",
        "model= vgg16(num_classes, fine_tune, pretrained)\n",
        "print(model)\n",
        "\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "if fine_tune:\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    params_to_update = model.parameters()\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "fqh39MlzHR7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MobileNet2"
      ],
      "metadata": {
        "id": "bP-fKqBtaUxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "layer_config= [2048, 512, 256]\n",
        "num_classes = 1\n",
        "num_epochs = 30\n",
        "batch_size = 200\n",
        "learning_rate = 1e-5\n",
        "learning_rate_decay = 0.99\n",
        "\n",
        "# Create mobilenet2 model pretrained with ImageNet\n",
        "class mobilenet_v2(nn.Module):\n",
        "    def __init__(self, n_class, fine_tune, pretrained=True):\n",
        "        super(mobilenet_v2, self).__init__()\n",
        "        self.net = models.mobilenet_v2(pretrained=pretrained)\n",
        "        \n",
        "        # add new classifier layers\n",
        "        '''self.net.classifier[6] = (nn.Sequential(\n",
        "            nn.Linear(4096, layer_config[0]),\n",
        "            nn.BatchNorm1d(layer_config[0]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[0], layer_config[1]),\n",
        "            nn.BatchNorm1d(layer_config[1]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[1], layer_config[2]),\n",
        "            nn.BatchNorm1d(layer_config[2]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[2], 1)\n",
        "        )) '''      \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        #return out\n",
        "        return out.view(-1, 1).squeeze(1).type(torch.FloatTensor) \n",
        "\n",
        "# Initialize the model for this run\n",
        "fine_tune = True\n",
        "pretrained = True\n",
        "model= vgg16(num_classes, fine_tune, pretrained)\n",
        "print(model)\n",
        "\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "if fine_tune:\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    params_to_update = model.parameters()\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "damBxmOHfATu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Alexnet"
      ],
      "metadata": {
        "id": "pRib382hbGpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "layer_config= [2048, 512, 256]\n",
        "num_classes = 23\n",
        "num_epochs = 20\n",
        "batch_size = 200\n",
        "learning_rate = 1e-5\n",
        "learning_rate_decay = 0.99\n",
        "\n",
        "# Create alexnet model pretrained with ImageNet\n",
        "class alexnet(nn.Module):\n",
        "    def __init__(self, n_class, fine_tune, pretrained=True):\n",
        "        super(alexnet, self).__init__()\n",
        "        self.net = models.alexnet(pretrained=pretrained)\n",
        "        \n",
        "        # add new classifier layers\n",
        "        self.net.classifier[6] = (nn.Sequential(\n",
        "            nn.Linear(4096, layer_config[0]),\n",
        "            nn.BatchNorm1d(layer_config[0]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[0], layer_config[1]),\n",
        "            nn.BatchNorm1d(layer_config[1]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[1], layer_config[2]),\n",
        "            nn.BatchNorm1d(layer_config[2]),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_config[2], num_classes),\n",
        "            nn.BatchNorm1d(23),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(23, 1)\n",
        "        ))      \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        #return out.type(torch.FloatTensor)\n",
        "        return out.view(-1, 1).squeeze(1).type(torch.FloatTensor) \n",
        "\n",
        "# Initialize the model for this run\n",
        "fine_tune = True\n",
        "pretrained = True\n",
        "model= alexnet(num_classes, fine_tune, pretrained)\n",
        "model.load_state_dict(torch.load('./drive/MyDrive/bestmodel_alexnet_dermnet.ckpt'), strict=False)\n",
        "\n",
        "print(model)\n",
        "\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "if fine_tune:\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    params_to_update = model.parameters()\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "hgI4Ti7cbJiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Finetuning on dermnet"
      ],
      "metadata": {
        "id": "93JazVoCpQBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_LAUNCH_BLOCKING=\"1\"\n",
        "\n",
        "\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# store best model and acc\n",
        "best_model_name = 'bestmodel_resnet_dermnet.ckpt'\n",
        "best_model = None\n",
        "best_val_acc = 0.\n",
        "\n",
        "\n",
        "loss_history = []\n",
        "val_loss_history = []\n",
        "train_acc_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
        "# Train the model\n",
        "lr = learning_rate\n",
        "total_step = len(dermnet_train_data_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    correct = 0\n",
        "    total = 0 \n",
        "    for i, (images, labels) in enumerate(dermnet_train_data_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images).to(device)\n",
        "        #predicted = torch.where(torch.sigmoid(outputs.data) > 0.5, 1, 0)\n",
        "        _, predicted = torch.max(outputs.data, 1) \n",
        "        loss = criterion(outputs, labels) # labels are stored as float need cast to int\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Train accuracy is: {} %'.format(100 * correct / total))\n",
        "    train_acc_history.append(100 * correct / total)\n",
        "    loss_history.append(loss.item())\n",
        "    \n",
        "    # Code to update the lr\n",
        "    lr *= learning_rate_decay\n",
        "    update_lr(optimizer, lr)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in dermnet_test_data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(images).to(device)\n",
        "            _, predicted = torch.max(outputs.data, 1) \n",
        "            #predicted = torch.where(torch.sigmoid(outputs.data) > 0.5, 1, 0)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "        val_accuracy = 100 * correct / total\n",
        "        if val_accuracy > best_val_acc:\n",
        "            best_val_acc = val_accuracy\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), best_model_name)\n",
        "            print(\"New best validation accuracy: {} %\".format(best_val_acc))\n",
        "\n",
        "\n",
        "        print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
        "        val_acc_history.append(val_accuracy)\n",
        "        val_loss_history.append(loss.item())\n",
        "  \n",
        "plt.plot(train_acc_history)\n",
        "plt.plot(val_acc_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy history')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# plot the loss history\n",
        "plt.plot(loss_history)\n",
        "plt.plot(val_loss_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss history')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w8_vcS78pWsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !cp './bestmodel_alexnet_dermnet.ckpt' './drive/MyDrive'\n"
      ],
      "metadata": {
        "id": "Sd78jP_ca44R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx-QnGYMNEzB"
      },
      "source": [
        "# Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_-FabsTwYqzA",
        "outputId": "60270b58-1e1e-4386-e8bd-9c9ffb4f6514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [1/20], Step [10/18], Loss: 0.6569\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 50.42016806722689 %\n",
            "New best validation accuracy: 44.827586206896555 %\n",
            "Validataion accuracy is: 44.827586206896555 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [2/20], Step [10/18], Loss: 0.6591\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 54.621848739495796 %\n",
            "New best validation accuracy: 56.32183908045977 %\n",
            "Validataion accuracy is: 56.32183908045977 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [3/20], Step [10/18], Loss: 0.6135\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 67.50700280112045 %\n",
            "New best validation accuracy: 70.11494252873563 %\n",
            "Validataion accuracy is: 70.11494252873563 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [4/20], Step [10/18], Loss: 0.5676\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 73.10924369747899 %\n",
            "New best validation accuracy: 72.41379310344827 %\n",
            "Validataion accuracy is: 72.41379310344827 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [5/20], Step [10/18], Loss: 0.4177\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 78.43137254901961 %\n",
            "Validataion accuracy is: 71.26436781609195 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [6/20], Step [10/18], Loss: 0.4640\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 82.63305322128852 %\n",
            "New best validation accuracy: 73.5632183908046 %\n",
            "Validataion accuracy is: 73.5632183908046 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [7/20], Step [10/18], Loss: 0.4442\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 82.07282913165267 %\n",
            "New best validation accuracy: 79.3103448275862 %\n",
            "Validataion accuracy is: 79.3103448275862 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [8/20], Step [10/18], Loss: 0.3518\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 85.15406162464986 %\n",
            "Validataion accuracy is: 79.3103448275862 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [9/20], Step [10/18], Loss: 0.3164\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 88.51540616246498 %\n",
            "Validataion accuracy is: 75.86206896551724 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [10/20], Step [10/18], Loss: 0.2182\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 89.07563025210084 %\n",
            "New best validation accuracy: 80.45977011494253 %\n",
            "Validataion accuracy is: 80.45977011494253 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [11/20], Step [10/18], Loss: 0.4192\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 91.03641456582633 %\n",
            "Validataion accuracy is: 80.45977011494253 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [12/20], Step [10/18], Loss: 0.1774\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 94.95798319327731 %\n",
            "Validataion accuracy is: 79.3103448275862 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [13/20], Step [10/18], Loss: 0.0884\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 94.39775910364146 %\n",
            "Validataion accuracy is: 78.16091954022988 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [14/20], Step [10/18], Loss: 0.1738\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 97.19887955182072 %\n",
            "Validataion accuracy is: 78.16091954022988 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [15/20], Step [10/18], Loss: 0.1100\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 98.59943977591037 %\n",
            "Validataion accuracy is: 78.16091954022988 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [16/20], Step [10/18], Loss: 0.1279\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 98.59943977591037 %\n",
            "New best validation accuracy: 82.75862068965517 %\n",
            "Validataion accuracy is: 82.75862068965517 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [17/20], Step [10/18], Loss: 0.0396\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 99.15966386554622 %\n",
            "Validataion accuracy is: 80.45977011494253 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [18/20], Step [10/18], Loss: 0.0677\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 99.15966386554622 %\n",
            "Validataion accuracy is: 81.60919540229885 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [19/20], Step [10/18], Loss: 0.0473\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 98.8795518207283 %\n",
            "Validataion accuracy is: 82.75862068965517 %\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "Epoch [20/20], Step [10/18], Loss: 0.0220\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "20 20\n",
            "17 17\n",
            "Train accuracy is: 99.43977591036415 %\n",
            "Validataion accuracy is: 81.60919540229885 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "CUDA_LAUNCH_BLOCKING=\"1\"\n",
        "\n",
        "\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# store best model and acc\n",
        "best_model_name = 'bestmodel_net_dermnetfinetuningnet.ckpt'\n",
        "best_model = None\n",
        "best_val_acc = 0.\n",
        "\n",
        "\n",
        "loss_history = []\n",
        "val_loss_history = []\n",
        "train_acc_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
        "# Train the model\n",
        "lr = learning_rate\n",
        "total_step = len(lyme_train_data_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    correct = 0\n",
        "    total = 0 \n",
        "    for i, (images, labels) in enumerate(lyme_train_data_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        print(len(images), len(labels))\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images).to(device)\n",
        "        predicted = torch.where(torch.sigmoid(outputs.data) > 0.5, 1, 0)\n",
        "        loss = criterion(outputs, labels.float()) # labels are stored as float need cast to int\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Train accuracy is: {} %'.format(100 * correct / total))\n",
        "    train_acc_history.append(100 * correct / total)\n",
        "    loss_history.append(loss.item())\n",
        "    \n",
        "    # Code to update the lr\n",
        "    lr *= learning_rate_decay\n",
        "    update_lr(optimizer, lr)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in lyme_test_data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(images).to(device)\n",
        "            predicted = torch.where(torch.sigmoid(outputs.data) > 0.5, 1, 0)\n",
        "            \n",
        "            loss = criterion(outputs, labels.float())\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "        val_accuracy = 100 * correct / total\n",
        "        if val_accuracy > best_val_acc:\n",
        "            best_val_acc = val_accuracy\n",
        "            best_model = model\n",
        "            print(\"New best validation accuracy: {} %\".format(best_val_acc))\n",
        "\n",
        "\n",
        "        print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
        "        val_acc_history.append(val_accuracy)\n",
        "        val_loss_history.append(loss.item())\n",
        "  \n",
        "plt.plot(train_acc_history)\n",
        "plt.plot(val_acc_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy history')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# plot the loss history\n",
        "plt.plot(loss_history)\n",
        "plt.plot(val_loss_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss history')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6E7_f4age90H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sigmoid(torch.tensor([0.2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cU4BN9Uwtj5",
        "outputId": "d76e468b-368f-40bc-cb82-fac8de390cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5498])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "|"
      ],
      "metadata": {
        "id": "ctULstGsmjj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lyme.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}