{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLCV Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62OCVFrnRZGx"
   },
   "outputs": [],
   "source": [
    "Name = \"Luisa Danalachi\"\n",
    "Matriculation_Number = \"7022909\"\n",
    "\n",
    "Name = \"Victor Martinez Palomares\"\n",
    "Matriculation_Number = \"7021729\"\n",
    "\n",
    "Name = \"Soham Roy\"\n",
    "Matriculation_Number = \"7028704\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "i6fBKi5dRdVQ",
    "outputId": "0010a4e7-2787-484b-bf7b-63d91a2469e7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !mkdir ./datasets\n",
    "# !mkdir ./datasets/lyme_dataset\n",
    "# !cp -r drive/MyDrive/Colab\\ Notebooks/HLCV_project/datasets/lyme_dataset.zip ./datasets\n",
    "# !unzip -q -o \"./datasets/lyme_dataset.zip\" -d \"./datasets/lyme_dataset\"\n",
    "\n",
    "# '''\n",
    "# !mkdir ./resources\n",
    "\n",
    "# !cp -r drive/MyDrive/Colab\\ Notebooks/HLCV/Exercise_3/resources/fig1.png ./resources\n",
    "# !cp -r drive/MyDrive/Colab\\ Notebooks/HLCV/Exercise_3/resources/fig2.png ./resources\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "nifGyyAjRiJd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRgAQ3OtKLeE"
   },
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTnqkXkIKKs8",
    "outputId": "13884d41-5022-45c1-a3c8-803fef14c658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 256\n",
    "EPOCHS = 120\n",
    "BATCH = 4\n",
    "LR = 1e-4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: %s'%device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "vc02dP-sWBLl",
    "outputId": "6df3bd1b-ad0a-4725-c651-6a78f33bb395"
   },
   "outputs": [],
   "source": [
    "data_aug_transforms = []\n",
    "\n",
    "data_aug_transforms.append(transforms.RandomRotation([-90, 90]) ) \n",
    "data_aug_transforms.append( transforms.RandomHorizontalFlip() )\n",
    "data_aug_transforms.append(transforms.ColorJitter(brightness = 0.2)) \n",
    "\n",
    "norm_transforms = [transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                   transforms.ToTensor(), \n",
    "                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "train_transforms = transforms.Compose(data_aug_transforms + norm_transforms)\n",
    "\n",
    "# Add Compose\n",
    "test_transforms =transforms.Compose(norm_transforms) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Lyme DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyme Dermnet data: Dataset ImageFolder\n",
      "    Number of datapoints: 357\n",
      "    Root location: ./datasets/Lyme/Train/Train_2_Cases\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ColorJitter(brightness=[0.8, 1.2], contrast=None, saturation=None, hue=None)\n",
      "               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n",
      "87\n",
      "Lyme classes: ['Lyme_Negative', 'Lyme_Positive']\n"
     ]
    }
   ],
   "source": [
    "#Load Lyme\n",
    "lyme_train_data_path = \"./datasets/Lyme/Train/Train_2_Cases\"\n",
    "lyme_test_data_path = \"./datasets/Lyme/Validation/Validation_2_Cases\"\n",
    "\n",
    "# ImageFolder is a generic data loader where the images are arranged in multiple folders\n",
    "\n",
    "#Load TRAIN\n",
    "lyme_train_data = torchvision.datasets.ImageFolder(root=lyme_train_data_path, transform=train_transforms)\n",
    "lyme_train_data_loader = data.DataLoader(lyme_train_data, batch_size=BATCH, shuffle=True)\n",
    "print(\"Lyme Dermnet data:\", lyme_train_data)\n",
    "\n",
    "# Load TEST \n",
    "lyme_test_data = torchvision.datasets.ImageFolder(root=lyme_test_data_path, transform=test_transforms)\n",
    "lyme_test_data_loader = data.DataLoader(lyme_test_data, batch_size=BATCH)\n",
    "print(len(lyme_test_data))\n",
    "# Check list of classes\n",
    "# Are converted to 0,1 etc when call enumerate()\n",
    "list_of_classes=list(map(str, list(lyme_train_data.classes)) )\n",
    "print(\"Lyme classes:\", list_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.1\n",
    "\n",
    "num_training = int((1 - val_split) * len(lyme_train_data))\n",
    "num_validation = len(lyme_train_data) - num_training\n",
    "mask = list(range(num_training))\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(lyme_train_data, mask)\n",
    "mask = list(range(num_training, num_training + num_validation))\n",
    "val_dataset = torch.utils.data.Subset(lyme_train_data, mask)\n",
    "\n",
    "# Create DataLoaders\n",
    "lyme_train_data_loader = data.DataLoader(train_dataset, batch_size=BATCH, shuffle=True, drop_last=True)\n",
    "lyme_validation_data_loader = data.DataLoader(val_dataset, batch_size=BATCH, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(lyme_test_data))\n",
    "\n",
    "print(len(lyme_train_data_loader))\n",
    "print(len(lyme_validation_data_loader))\n",
    "print(len(lyme_test_data_loader)) #did not add drop_last=True to TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator=iter(lyme_validation_data_loader)\n",
    "# inputs, classes = next(iterator)\n",
    "# print(len(inputs)) \n",
    "\n",
    "# plt.imshow(inputs[0].squeeze().permute(2,1,0))\n",
    "# plt.show()\n",
    "# print(\"CLass: \",classes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dermnet DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details Dermnet data: Dataset ImageFolder\n",
      "    Number of datapoints: 15557\n",
      "    Root location: ./datasets/Dermnet/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ColorJitter(brightness=[0.8, 1.2], contrast=None, saturation=None, hue=None)\n",
      "               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n",
      "Dermnet classes ['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
     ]
    }
   ],
   "source": [
    "#Load Dermnet\n",
    "dermnet_train_data_path = \"./datasets/Dermnet/train\"\n",
    "dermnet_test_data_path = \"./datasets/Dermnet/test\"\n",
    "\n",
    "# ImageFolder is a generic data loader where the images are arranged in multiple folders\n",
    "dermnet_train_data = torchvision.datasets.ImageFolder(root=dermnet_train_data_path, transform=train_transforms)\n",
    "dermnet_train_data_loader = data.DataLoader(dermnet_train_data, batch_size=BATCH, shuffle=True)\n",
    "print(\"Details Dermnet data:\", dermnet_train_data)\n",
    "\n",
    "# Load test \n",
    "dermnet_test_data = torchvision.datasets.ImageFolder(root=dermnet_test_data_path, transform=test_transforms)\n",
    "dermnet_test_data_loader = data.DataLoader(dermnet_train_data, batch_size=BATCH)\n",
    "\n",
    "# Load list of classes\n",
    "list_of_classes=list(map(str, list(dermnet_train_data.classes)) )\n",
    "print(\"Dermnet classes\", list_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load HAM DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_df = pd.read_csv('./datasets/HAM100/HAM10000_metadata.csv')\n",
    "ham_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract images based on their label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take labels\n",
    "name_labels = ham_df[\"dx\"].unique()\n",
    "\n",
    "# Create folders with the label name and add the corresponding images -> Must for using ImageFolder!\n",
    "\n",
    "for label in range(len(name_labels)):\n",
    "    # create folder for each label\n",
    "    label_folder_path = \"./datasets/HAM10000/train/\" + str(name_labels[label])\n",
    "    \n",
    "    # check is path exists if not create folder\n",
    "    if not os.path.exists(label_folder_path):\n",
    "        os.mkdir('./datasets/HAM10000/train/' + name_labels[label] + \"/\" )\n",
    "    \n",
    "    # take the image id corresponding to label\n",
    "    image_names =  ham_df[ham_df['dx'] == name_labels[label]]['image_id']\n",
    "    \n",
    "    # iterate through all image names \n",
    "    for image in image_names:\n",
    "        # create the path for image: either part 1 or part 2\n",
    "        path_folder_1 = \"./datasets/HAM10000/HAM10000_images_part_1/\" + image + \".jpg\"\n",
    "        path_folder_2 = \"./datasets/HAM10000/HAM10000_images_part_2/\" + image + \".jpg\"\n",
    "        \n",
    "        # find where is the image and copy it into the label folder\n",
    "        if os.path.exists(path_folder_1):\n",
    "            shutil.copyfile(path_folder_1, './datasets/HAM10000/train/' + name_labels[label] + \"/\" + image + \".jpg\")\n",
    "        else:\n",
    "            shutil.copyfile(path_folder_2, './datasets/HAM10000/train/' + name_labels[label] + \"/\" + image + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM1000 Dermnet data: Dataset ImageFolder\n",
      "    Number of datapoints: 10015\n",
      "    Root location: ./datasets/HAM10000/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ColorJitter(brightness=[0.8, 1.2], contrast=None, saturation=None, hue=None)\n",
      "               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n",
      "HAM1000 classes ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "#Load Dermnet\n",
    "HAM_train_data_path = \"./datasets/HAM10000/train\"\n",
    "\n",
    "# ImageFolder is a generic data loader where the images are arranged in multiple folders\n",
    "ham_train_data = torchvision.datasets.ImageFolder(root=HAM_train_data_path, transform=train_transforms)\n",
    "ham_train_data_loader = data.DataLoader(ham_train_data, batch_size=BATCH, shuffle=True)\n",
    "print(\"HAM1000 Dermnet data:\", ham_train_data)\n",
    "\n",
    "# # Load list of classes\n",
    "list_of_classes=list(map(str, list(ham_train_data.classes)) )\n",
    "print(\"HAM1000 classes\", list_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSDvF5JPQbDS"
   },
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ct4o47mpQeMc",
    "outputId": "bc098a58-fc09-4300-dd4e-c1405d4aefa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50(\n",
      "  (net): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Params to learn:\n",
      "\t net.conv1.weight\n",
      "\t net.bn1.weight\n",
      "\t net.bn1.bias\n",
      "\t net.layer1.0.conv1.weight\n",
      "\t net.layer1.0.bn1.weight\n",
      "\t net.layer1.0.bn1.bias\n",
      "\t net.layer1.0.conv2.weight\n",
      "\t net.layer1.0.bn2.weight\n",
      "\t net.layer1.0.bn2.bias\n",
      "\t net.layer1.0.conv3.weight\n",
      "\t net.layer1.0.bn3.weight\n",
      "\t net.layer1.0.bn3.bias\n",
      "\t net.layer1.0.downsample.0.weight\n",
      "\t net.layer1.0.downsample.1.weight\n",
      "\t net.layer1.0.downsample.1.bias\n",
      "\t net.layer1.1.conv1.weight\n",
      "\t net.layer1.1.bn1.weight\n",
      "\t net.layer1.1.bn1.bias\n",
      "\t net.layer1.1.conv2.weight\n",
      "\t net.layer1.1.bn2.weight\n",
      "\t net.layer1.1.bn2.bias\n",
      "\t net.layer1.1.conv3.weight\n",
      "\t net.layer1.1.bn3.weight\n",
      "\t net.layer1.1.bn3.bias\n",
      "\t net.layer1.2.conv1.weight\n",
      "\t net.layer1.2.bn1.weight\n",
      "\t net.layer1.2.bn1.bias\n",
      "\t net.layer1.2.conv2.weight\n",
      "\t net.layer1.2.bn2.weight\n",
      "\t net.layer1.2.bn2.bias\n",
      "\t net.layer1.2.conv3.weight\n",
      "\t net.layer1.2.bn3.weight\n",
      "\t net.layer1.2.bn3.bias\n",
      "\t net.layer2.0.conv1.weight\n",
      "\t net.layer2.0.bn1.weight\n",
      "\t net.layer2.0.bn1.bias\n",
      "\t net.layer2.0.conv2.weight\n",
      "\t net.layer2.0.bn2.weight\n",
      "\t net.layer2.0.bn2.bias\n",
      "\t net.layer2.0.conv3.weight\n",
      "\t net.layer2.0.bn3.weight\n",
      "\t net.layer2.0.bn3.bias\n",
      "\t net.layer2.0.downsample.0.weight\n",
      "\t net.layer2.0.downsample.1.weight\n",
      "\t net.layer2.0.downsample.1.bias\n",
      "\t net.layer2.1.conv1.weight\n",
      "\t net.layer2.1.bn1.weight\n",
      "\t net.layer2.1.bn1.bias\n",
      "\t net.layer2.1.conv2.weight\n",
      "\t net.layer2.1.bn2.weight\n",
      "\t net.layer2.1.bn2.bias\n",
      "\t net.layer2.1.conv3.weight\n",
      "\t net.layer2.1.bn3.weight\n",
      "\t net.layer2.1.bn3.bias\n",
      "\t net.layer2.2.conv1.weight\n",
      "\t net.layer2.2.bn1.weight\n",
      "\t net.layer2.2.bn1.bias\n",
      "\t net.layer2.2.conv2.weight\n",
      "\t net.layer2.2.bn2.weight\n",
      "\t net.layer2.2.bn2.bias\n",
      "\t net.layer2.2.conv3.weight\n",
      "\t net.layer2.2.bn3.weight\n",
      "\t net.layer2.2.bn3.bias\n",
      "\t net.layer2.3.conv1.weight\n",
      "\t net.layer2.3.bn1.weight\n",
      "\t net.layer2.3.bn1.bias\n",
      "\t net.layer2.3.conv2.weight\n",
      "\t net.layer2.3.bn2.weight\n",
      "\t net.layer2.3.bn2.bias\n",
      "\t net.layer2.3.conv3.weight\n",
      "\t net.layer2.3.bn3.weight\n",
      "\t net.layer2.3.bn3.bias\n",
      "\t net.layer3.0.conv1.weight\n",
      "\t net.layer3.0.bn1.weight\n",
      "\t net.layer3.0.bn1.bias\n",
      "\t net.layer3.0.conv2.weight\n",
      "\t net.layer3.0.bn2.weight\n",
      "\t net.layer3.0.bn2.bias\n",
      "\t net.layer3.0.conv3.weight\n",
      "\t net.layer3.0.bn3.weight\n",
      "\t net.layer3.0.bn3.bias\n",
      "\t net.layer3.0.downsample.0.weight\n",
      "\t net.layer3.0.downsample.1.weight\n",
      "\t net.layer3.0.downsample.1.bias\n",
      "\t net.layer3.1.conv1.weight\n",
      "\t net.layer3.1.bn1.weight\n",
      "\t net.layer3.1.bn1.bias\n",
      "\t net.layer3.1.conv2.weight\n",
      "\t net.layer3.1.bn2.weight\n",
      "\t net.layer3.1.bn2.bias\n",
      "\t net.layer3.1.conv3.weight\n",
      "\t net.layer3.1.bn3.weight\n",
      "\t net.layer3.1.bn3.bias\n",
      "\t net.layer3.2.conv1.weight\n",
      "\t net.layer3.2.bn1.weight\n",
      "\t net.layer3.2.bn1.bias\n",
      "\t net.layer3.2.conv2.weight\n",
      "\t net.layer3.2.bn2.weight\n",
      "\t net.layer3.2.bn2.bias\n",
      "\t net.layer3.2.conv3.weight\n",
      "\t net.layer3.2.bn3.weight\n",
      "\t net.layer3.2.bn3.bias\n",
      "\t net.layer3.3.conv1.weight\n",
      "\t net.layer3.3.bn1.weight\n",
      "\t net.layer3.3.bn1.bias\n",
      "\t net.layer3.3.conv2.weight\n",
      "\t net.layer3.3.bn2.weight\n",
      "\t net.layer3.3.bn2.bias\n",
      "\t net.layer3.3.conv3.weight\n",
      "\t net.layer3.3.bn3.weight\n",
      "\t net.layer3.3.bn3.bias\n",
      "\t net.layer3.4.conv1.weight\n",
      "\t net.layer3.4.bn1.weight\n",
      "\t net.layer3.4.bn1.bias\n",
      "\t net.layer3.4.conv2.weight\n",
      "\t net.layer3.4.bn2.weight\n",
      "\t net.layer3.4.bn2.bias\n",
      "\t net.layer3.4.conv3.weight\n",
      "\t net.layer3.4.bn3.weight\n",
      "\t net.layer3.4.bn3.bias\n",
      "\t net.layer3.5.conv1.weight\n",
      "\t net.layer3.5.bn1.weight\n",
      "\t net.layer3.5.bn1.bias\n",
      "\t net.layer3.5.conv2.weight\n",
      "\t net.layer3.5.bn2.weight\n",
      "\t net.layer3.5.bn2.bias\n",
      "\t net.layer3.5.conv3.weight\n",
      "\t net.layer3.5.bn3.weight\n",
      "\t net.layer3.5.bn3.bias\n",
      "\t net.layer4.0.conv1.weight\n",
      "\t net.layer4.0.bn1.weight\n",
      "\t net.layer4.0.bn1.bias\n",
      "\t net.layer4.0.conv2.weight\n",
      "\t net.layer4.0.bn2.weight\n",
      "\t net.layer4.0.bn2.bias\n",
      "\t net.layer4.0.conv3.weight\n",
      "\t net.layer4.0.bn3.weight\n",
      "\t net.layer4.0.bn3.bias\n",
      "\t net.layer4.0.downsample.0.weight\n",
      "\t net.layer4.0.downsample.1.weight\n",
      "\t net.layer4.0.downsample.1.bias\n",
      "\t net.layer4.1.conv1.weight\n",
      "\t net.layer4.1.bn1.weight\n",
      "\t net.layer4.1.bn1.bias\n",
      "\t net.layer4.1.conv2.weight\n",
      "\t net.layer4.1.bn2.weight\n",
      "\t net.layer4.1.bn2.bias\n",
      "\t net.layer4.1.conv3.weight\n",
      "\t net.layer4.1.bn3.weight\n",
      "\t net.layer4.1.bn3.bias\n",
      "\t net.layer4.2.conv1.weight\n",
      "\t net.layer4.2.bn1.weight\n",
      "\t net.layer4.2.bn1.bias\n",
      "\t net.layer4.2.conv2.weight\n",
      "\t net.layer4.2.bn2.weight\n",
      "\t net.layer4.2.bn2.bias\n",
      "\t net.layer4.2.conv3.weight\n",
      "\t net.layer4.2.bn3.weight\n",
      "\t net.layer4.2.bn3.bias\n",
      "\t net.fc.1.weight\n",
      "\t net.fc.1.bias\n",
      "\t net.fc.2.weight\n",
      "\t net.fc.2.bias\n",
      "\t net.fc.4.weight\n",
      "\t net.fc.4.bias\n",
      "\t net.fc.5.weight\n",
      "\t net.fc.5.bias\n",
      "\t net.fc.7.weight\n",
      "\t net.fc.7.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (net): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "#from torchvision.models import ResNet50_Weights\n",
    "\n",
    "layer_config= [2048, 512, 256]\n",
    "num_classes = 1\n",
    "num_epochs = 30\n",
    "batch_size = 200\n",
    "learning_rate = 1e-5\n",
    "learning_rate_decay = 0.99\n",
    "\n",
    "# Create ResNet 50 model pretrained with ImageNet\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, n_class, fine_tune, pretrained=True):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.net = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # add new classifier layers\n",
    "        self.net.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(layer_config[0], layer_config[1]),\n",
    "            nn.BatchNorm1d(layer_config[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_config[1], layer_config[2]),\n",
    "            nn.BatchNorm1d(layer_config[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_config[2], n_class)\n",
    "        )       \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out.view(-1, 1).squeeze(1).type(torch.FloatTensor) \n",
    "\n",
    "# Initialize the model for this run\n",
    "fine_tune = True\n",
    "pretrained = True\n",
    "model= ResNet50(num_classes, fine_tune, pretrained)\n",
    "print(model)\n",
    "\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if fine_tune:\n",
    "    params_to_update = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    params_to_update = model.parameters()\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-FabsTwYqzA",
    "outputId": "ab944b36-65e8-419a-8bd3-2c8a33ad789e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [10/80], Loss: 0.9022\n",
      "Epoch [1/30], Step [20/80], Loss: 0.7290\n",
      "Epoch [1/30], Step [30/80], Loss: 0.6306\n",
      "Epoch [1/30], Step [40/80], Loss: 0.6624\n",
      "Epoch [1/30], Step [50/80], Loss: 0.6195\n",
      "Epoch [1/30], Step [60/80], Loss: 0.5262\n",
      "Epoch [1/30], Step [70/80], Loss: 0.6554\n",
      "Epoch [1/30], Step [80/80], Loss: 0.5904\n",
      "Train accuracy is: 61.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation accuracy: 52.77777777777778 %\n",
      "Validataion accuracy is: 52.77777777777778 %\n",
      "Epoch [2/30], Step [10/80], Loss: 0.7072\n",
      "Epoch [2/30], Step [20/80], Loss: 0.6132\n",
      "Epoch [2/30], Step [30/80], Loss: 0.6954\n",
      "Epoch [2/30], Step [40/80], Loss: 0.6038\n",
      "Epoch [2/30], Step [50/80], Loss: 0.7589\n",
      "Epoch [2/30], Step [60/80], Loss: 0.7372\n",
      "Epoch [2/30], Step [70/80], Loss: 0.4736\n",
      "Epoch [2/30], Step [80/80], Loss: 0.4997\n",
      "Train accuracy is: 68.125 %\n",
      "Validataion accuracy is: 50.0 %\n",
      "Epoch [3/30], Step [10/80], Loss: 0.6842\n",
      "Epoch [3/30], Step [20/80], Loss: 0.4575\n",
      "Epoch [3/30], Step [30/80], Loss: 0.4991\n",
      "Epoch [3/30], Step [40/80], Loss: 0.6572\n",
      "Epoch [3/30], Step [50/80], Loss: 0.4382\n",
      "Epoch [3/30], Step [60/80], Loss: 0.7709\n",
      "Epoch [3/30], Step [70/80], Loss: 0.6667\n",
      "Epoch [3/30], Step [80/80], Loss: 0.5107\n",
      "Train accuracy is: 71.25 %\n",
      "Validataion accuracy is: 47.22222222222222 %\n",
      "Epoch [4/30], Step [10/80], Loss: 0.4601\n",
      "Epoch [4/30], Step [20/80], Loss: 0.7833\n",
      "Epoch [4/30], Step [30/80], Loss: 0.5755\n",
      "Epoch [4/30], Step [40/80], Loss: 0.5842\n",
      "Epoch [4/30], Step [50/80], Loss: 0.4561\n",
      "Epoch [4/30], Step [60/80], Loss: 0.4956\n",
      "Epoch [4/30], Step [70/80], Loss: 0.6786\n",
      "Epoch [4/30], Step [80/80], Loss: 0.7552\n",
      "Train accuracy is: 71.5625 %\n",
      "Validataion accuracy is: 52.77777777777778 %\n",
      "Epoch [5/30], Step [10/80], Loss: 0.6512\n",
      "Epoch [5/30], Step [20/80], Loss: 0.5648\n",
      "Epoch [5/30], Step [30/80], Loss: 0.6207\n",
      "Epoch [5/30], Step [40/80], Loss: 0.6346\n",
      "Epoch [5/30], Step [50/80], Loss: 0.5998\n",
      "Epoch [5/30], Step [60/80], Loss: 0.6163\n",
      "Epoch [5/30], Step [70/80], Loss: 0.7035\n",
      "Epoch [5/30], Step [80/80], Loss: 0.3923\n",
      "Train accuracy is: 72.1875 %\n",
      "Validataion accuracy is: 50.0 %\n",
      "Epoch [6/30], Step [10/80], Loss: 0.4834\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1e808f41d09b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n\u001b[0;32m     47\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train accuracy is: {} %'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mtrain_acc_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CUDA_LAUNCH_BLOCKING=\"1\"\n",
    "\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# store best model and acc\n",
    "best_model_name = 'bestmodel_resnet50_imagenet.ckpt'\n",
    "best_model = None\n",
    "best_val_acc = 0.\n",
    "\n",
    "\n",
    "loss_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(lyme_train_data_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    for i, (images, labels) in enumerate(lyme_train_data_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images).to(device)\n",
    "        predicted = torch.where(torch.sigmoid(outputs.data) > 0.5, 1, 0)\n",
    "        loss = criterion(outputs, labels.float()) # labels are stored as float need cast to int\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Train accuracy is: {} %'.format(100 * correct / total))\n",
    "    train_acc_history.append(100 * correct / total)\n",
    "    loss_history.append(loss.item())\n",
    "    \n",
    "    # Code to update the lr\n",
    "    lr *= learning_rate_decay\n",
    "    update_lr(optimizer, lr)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in lyme_validation_data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images).to(device)\n",
    "            predicted = torch.where(torch.sigmoid(outputs.data) > 0.5, 1, 0)\n",
    "            \n",
    "            loss = criterion(outputs, labels.float())\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        val_accuracy = 100 * correct / total\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            best_model = model\n",
    "            print(\"New best validation accuracy: {} %\".format(best_val_acc))\n",
    "\n",
    "\n",
    "        print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
    "        val_acc_history.append(val_accuracy)\n",
    "        val_loss_history.append(loss.item())\n",
    "  \n",
    "plt.plot(train_acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy history')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.plot(val_loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss history')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn-lyme-detection.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
